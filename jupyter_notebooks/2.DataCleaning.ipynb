{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Encode categorical variables and deal with missing data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousePricesRecords.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Create a pipeline that carries out a data cleaning process\n",
        "* outputs/datasets/collection/housing_data_cleaned.csv\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "* Variables with around 90% missing data have been dropped.\n",
        "* Any variables with missing data have had the median value entered in place\n",
        "* The 4 object variables have been encoded\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\"))\n",
        "df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Encode the object variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **BsmtExposure:** Gd: Good Exposure; Av: Average Exposure; Mn: Minimum Exposure; No: No Exposure; None: No Basement\n",
        "* **BsmtFinType1:** GLQ: Good Living Quarters; ALQ: Average Living Quarters; BLQ: Below Average Living Quarters; Rec: Average Rec Room; LwQ: Low Quality; Unf: Unfinshed; None: No Basement\n",
        "* **GarageFinish:** Fin: Finished; RFn: Rough Finished; Unf: Unfinished; None: No Garage\n",
        "* **KitchenQual:** Kitchen quality Ex: Excellent; Gd: Good; TA: Typical/Average; Fa: Fair; Po: Poor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dictionary to change the categories of these variables to numbers\n",
        "dic = {'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'nan': 0, 'Missing': 0}, 'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}, 'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}, 'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
        "df1=df.copy()\n",
        "for col in df.columns[df.dtypes=='object'].to_list():\n",
        "    df1[col] = df1[col].replace(dic[col])\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "# create a Class variable to fit and transform\n",
        "class MyCustomEncoder(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variables, dic):\n",
        "    if not isinstance(variables, list): \n",
        "      self.variables = [variables]\n",
        "    else: self.variables = variables\n",
        "    self.dic = dic\n",
        "\n",
        "  def fit(self, X, y=None):    \n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    for col in self.variables:\n",
        "      if X[col].dtype == 'object':\n",
        "        X[col] = X[col].replace(dic[col])\n",
        "      else:\n",
        "        print(f\"Warning: {col} data type should be object to use MyCustomEncoder()\")\n",
        "      \n",
        "    return X\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline([('custom_encoder', MyCustomEncoder(variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'], dic=dic))])\n",
        "\n",
        "df1 = df.copy()\n",
        "df1 = pipeline.fit_transform(df1)\n",
        "df1.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take the missing data vars and put them into a column to pass into a summary report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pass the missing data into a profile report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Drop Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After viewing the summary we can see that there are 2 variables with 90% missing data so they can be dropped. These variables are 'EnclosedPorch', 'WoodDeckSF'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "drop_features = DropFeatures(features_to_drop = ['EnclosedPorch', 'WoodDeckSF'])\n",
        "\n",
        "df_transformed = drop_features.fit_transform(df)\n",
        "df_transformed.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Replace Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we will replace the missing data with the median values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will remove the 'EnclosedPorch' and 'WoodDeckSF' as we have already dropped them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = ['2ndFlrSF', 'BedroomAbvGr', 'BsmtFinType1', 'GarageFinish', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea']\n",
        "\n",
        "from feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "      ('drop_features', DropFeatures(features_to_drop = ['EnclosedPorch', 'WoodDeckSF'])),\n",
        "      ('categorical_imputer', CategoricalImputer(imputation_method='missing', variables=['BsmtExposure'])),\n",
        "      ('custom_encoder', MyCustomEncoder(variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'], dic=dic)),\n",
        "      ('median_imputer',  MeanMedianImputer(imputation_method='median', variables=vars_with_missing_data))\n",
        "])\n",
        "\n",
        "df1 = df.copy()\n",
        "df_transformed = pipeline.fit_transform(df1) \n",
        "df_transformed.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will check that there is no missing data left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df_transformed.columns[df_transformed.isna().sum() > 0].to_list()\n",
        "\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline['median_imputer'].imputer_dict_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "output_dir = \"/workspace/PP5-ML-PROJECT/outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "cleaned_file_path = os.path.join(output_dir, \"housing_data_cleaned.csv\")\n",
        "df_transformed.to_csv(cleaned_file_path, index=False)\n",
        "\n",
        "print(f\"Cleaned dataset saved at: {cleaned_file_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
