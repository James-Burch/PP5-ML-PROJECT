{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Modeling and Evaluation - Predict House Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fit and evaluate a classification model to predict a house sale price when the house features are known.\n",
        "\n",
        "## Inputs\n",
        "* outputs/datasets/collection/HousePricesRecords.csv\n",
        "* Feature engineering/data cleaning from the feature engineering notebook.\n",
        "\n",
        "## Outputs \n",
        "* Train set\n",
        "* Test set\n",
        "* ML pipeline to predict house sale prices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/PP5-ML-PROJECT/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/PP5-ML-PROJECT'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>...</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856.0</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706.0</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978.0</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>460.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486.0</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>608.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216.0</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>642.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655.0</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>836.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>796.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>732.0</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>480.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>...</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>796.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1993</td>\n",
              "      <td>1995</td>\n",
              "      <td>143000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1694.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>1369.0</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>317.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>636.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>75.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1686.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2004</td>\n",
              "      <td>2005</td>\n",
              "      <td>307000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1107.0</td>\n",
              "      <td>983.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>859.0</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>484.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>240.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1973</td>\n",
              "      <td>1973</td>\n",
              "      <td>200000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1022.0</td>\n",
              "      <td>752.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>952.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>468.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>952.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1931</td>\n",
              "      <td>1950</td>\n",
              "      <td>129900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1077.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>851.0</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>140.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>205.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>991.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1939</td>\n",
              "      <td>1950</td>\n",
              "      <td>118000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0     856.0     854.0           3.0           No       706.0          GLQ   \n",
              "1    1262.0       0.0           3.0           Gd       978.0          ALQ   \n",
              "2     920.0     866.0           3.0           Mn       486.0          GLQ   \n",
              "3     961.0       NaN           NaN           No       216.0          ALQ   \n",
              "4    1145.0       NaN           4.0           Av       655.0          GLQ   \n",
              "5     796.0     566.0           1.0           No       732.0          GLQ   \n",
              "6    1694.0       0.0           3.0           Av      1369.0          GLQ   \n",
              "7    1107.0     983.0           3.0           Mn       859.0          ALQ   \n",
              "8    1022.0     752.0           2.0           No         0.0          Unf   \n",
              "9    1077.0       0.0           2.0           No       851.0          GLQ   \n",
              "\n",
              "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
              "0      150.0            0.0       548.0          RFn  ...         65.0   \n",
              "1      284.0            NaN       460.0          RFn  ...         80.0   \n",
              "2      434.0            0.0       608.0          RFn  ...         68.0   \n",
              "3      540.0            NaN       642.0          Unf  ...         60.0   \n",
              "4      490.0            0.0       836.0          RFn  ...         84.0   \n",
              "5       64.0            NaN       480.0          Unf  ...         85.0   \n",
              "6      317.0            NaN       636.0          RFn  ...         75.0   \n",
              "7      216.0            NaN       484.0          NaN  ...          NaN   \n",
              "8      952.0            NaN       468.0          Unf  ...         51.0   \n",
              "9      140.0            NaN       205.0          RFn  ...         50.0   \n",
              "\n",
              "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
              "0       196.0        61.0            5            7        856.0         0.0   \n",
              "1         0.0         0.0            8            6       1262.0         NaN   \n",
              "2       162.0        42.0            5            7        920.0         NaN   \n",
              "3         0.0        35.0            5            7        756.0         NaN   \n",
              "4       350.0        84.0            5            8       1145.0         NaN   \n",
              "5         0.0        30.0            5            5        796.0         NaN   \n",
              "6       186.0        57.0            5            8       1686.0         NaN   \n",
              "7       240.0       204.0            6            7       1107.0         NaN   \n",
              "8         0.0         0.0            5            7        952.0         NaN   \n",
              "9         0.0         4.0            6            5        991.0         NaN   \n",
              "\n",
              "   YearBuilt  YearRemodAdd  SalePrice  \n",
              "0       2003          2003   208500.0  \n",
              "1       1976          1976   181500.0  \n",
              "2       2001          2002   223500.0  \n",
              "3       1915          1970   140000.0  \n",
              "4       2000          2000   250000.0  \n",
              "5       1993          1995   143000.0  \n",
              "6       2004          2005   307000.0  \n",
              "7       1973          1973   200000.0  \n",
              "8       1931          1950   129900.0  \n",
              "9       1939          1950   118000.0  \n",
              "\n",
              "[10 rows x 24 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\"))\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML pipeline for data cleaning and feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Encoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class MyCustomEncoder(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variables, dic):\n",
        "    if not isinstance(variables, list): \n",
        "      self.variables = [variables]\n",
        "    else: self.variables = variables\n",
        "    self.dic = dic\n",
        "\n",
        "  def fit(self, X, y=None):    \n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    X = X.copy()\n",
        "    for col in self.variables:\n",
        "        if X[col].dtype == 'object':\n",
        "            if col in self.dic:  \n",
        "                X[col] = X[col].replace(self.dic[col])\n",
        "            else:\n",
        "                print(f\"Warning: No mapping found for column {col}\")\n",
        "        else:\n",
        "            print(f\"Warning: {col} data type should be object to use MyCustomEncoder()\")\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Import all necassary ML algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bring in the pipeline from the feature engineering notebook with feature scaling, feature selection and model added:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms \n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "def PipelineOptimization(dic, numeric_vars, model):\n",
        "    \n",
        "      pipeline = Pipeline([       \n",
        "            ('drop_features', DropFeatures(features_to_drop = ['EnclosedPorch', 'WoodDeckSF'])),\n",
        "     \n",
        "            ('custom_encoder', MyCustomEncoder(variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'], dic=dic)),\n",
        "            \n",
        "            ('median_imputer',  MeanMedianImputer(imputation_method='median', variables=numeric_vars)),\n",
        "            \n",
        "            ('corr_sel', SmartCorrelatedSelection(method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
        "            \n",
        "            (\"feat_scaling\", StandardScaler() ),\n",
        "\n",
        "            (\"feat_selection\",  SelectFromModel(model) ),\n",
        "\n",
        "            (\"model\", model ),\n",
        "      ])\n",
        "\n",
        "      return pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Hyperparameter optimization**: Custom hyperparameter optimization to fit my model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, dic, numeric_vars, models, params):\n",
        "        self.dic = dic\n",
        "        self.numeric_vars = numeric_vars\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineOptimization(dic, numeric_vars, self.models[key],)\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(np.array(r).reshape(-1, 1))\n",
        "\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split the data into Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Set: (1168, 23) (1168,) Test Set: (292, 23) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['SalePrice'], axis=1),\n",
        "    df['SalePrice'],\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print('Train Set:', X_train.shape, y_train.shape, 'Test Set:', X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV from Scikit Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets try 7 ML models to find the best one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "dic = {'BsmtExposure': {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'None': 0}, 'BsmtFinType1': {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'None': 0}, 'GarageFinish': {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}, 'KitchenQual': {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1, 'Po': 0}}\n",
        "\n",
        "# Variables with missing variables after dropping ['EnclosedPorch', 'WoodDeckSF']. This is a parameter passed to MeanMedianImputer\n",
        "numeric_vars = ['2ndFlrSF', 'BedroomAbvGr', 'BsmtFinType1', 'GarageFinish', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea']   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for DecisionTreeRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for RandomForestRegressor \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[38;5;241m=\u001b[39m HyperparameterOptimizationSearch(dic\u001b[38;5;241m=\u001b[39mdic, numeric_vars\u001b[38;5;241m=\u001b[39mnumeric_vars, models\u001b[38;5;241m=\u001b[39mmodels_quick_search, params\u001b[38;5;241m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     18\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[key]\n\u001b[1;32m     19\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_searches[key] \u001b[38;5;241m=\u001b[39m gs\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py\", line 358, in fit\n    self.estimator_.fit(X, y, **fit_params)\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/workspace/.pip-modules/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
          ]
        }
      ],
      "source": [
        "search = HyperparameterOptimizationSearch(dic=dic, numeric_vars=numeric_vars, models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
